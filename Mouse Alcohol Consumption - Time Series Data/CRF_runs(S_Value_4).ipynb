{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. from 'CRF_2022-01-27_T1Close.ipynb'\n",
    "# 2. removed unused cells (except pairplot), sequentially re-labeled cells\n",
    "# 3. notebook functional\n",
    "\n",
    "# Cell 1\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Cell 2\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import plotly_express as px\n",
    "#import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.offline import plot, iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "import time\n",
    "import warnings\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from lightgbm import LGBMRegressor\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3\n",
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in data and check data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4\n",
    "df = pd.read_csv('C:/0-Ubi/S_Value_3.csv')\n",
    "df = df.iloc[:,1:]\n",
    "df = df.drop(61)\n",
    "df.index = pd.RangeIndex(len(df.index))\n",
    "df2 = df.copy()\n",
    "df.shape, df.dtypes, df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "df.columns = df.columns.str.replace('[', '')\n",
    "df.columns = df.columns.str.replace(']', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7\n",
    "# correlation\n",
    "cor = df.corr()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8\n",
    "\n",
    "sns.heatmap(cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9\n",
    "df.drop(['Date',\n",
    " 'Time',\n",
    "] ,axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10\n",
    "df.iloc[1:5,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split data for train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11\n",
    "y = df.V_Close\n",
    "x = df.drop(['V_C_target'], axis = 1)\n",
    "xtrain, xtest, ytrain,ytest = train_test_split(x,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12\n",
    "train = df2.iloc[xtrain.index]\n",
    "test = df2.iloc[xtest.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 13\n",
    "scaler = StandardScaler()\n",
    "xtrain.iloc[:,:] = scaler.fit_transform(xtrain.iloc[:,:])\n",
    "xtest.iloc[:,:] = scaler.transform(xtest.iloc[:,:])\n",
    "# Xiaoyan's 01-20 code: removed numbers inside square brackets\n",
    "# still has the same caveats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "models and comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14\n",
    "# linear regression\n",
    "lr = LinearRegression()\n",
    "lr.fit(xtrain, ytrain)\n",
    "lr_confidence = lr.score(xtest, ytest)\n",
    "train['linear_regression'] = lr.predict(xtrain)\n",
    "test['linear_regression']=lr.predict(xtest)\n",
    "lr_mse = mean_squared_error(ytest, test['linear_regression'])\n",
    "lr_confidence, lr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15\n",
    "# ranom forest\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(xtrain, ytrain)\n",
    "rf_confidence = rf.score(xtest, ytest)\n",
    "train['ranom_forest'] = rf.predict(xtrain)\n",
    "test['ranom_forest']=rf.predict(xtest)\n",
    "rf_mse = mean_squared_error(ytest, test['ranom_forest'])\n",
    "rf_confidence,rf_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16\n",
    "# ridge\n",
    "rg = Ridge()\n",
    "rg.fit(xtrain, ytrain)\n",
    "rg_confidence = rg.score(xtest, ytest)\n",
    "train['ridge'] = rg.predict(xtrain)\n",
    "test['ridge']=rg.predict(xtest)\n",
    "rg_mse = mean_squared_error(ytest, test['ridge'])\n",
    "rg_confidence, rg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17\n",
    "# xgboost\n",
    "# Import xgboost\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Create the training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "# Instantiate the XGBRegressor: xg_reg\n",
    "xg_reg = xgb.XGBRegressor(objective=\"reg:linear\", n_estimators=10, seed=123)\n",
    "\n",
    "# Fit the regressor to the training set\n",
    "xg_reg.fit(xtrain, ytrain)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg.predict(xtest)\n",
    "\n",
    "# Compute the rmse: rmse\n",
    "rmse = np.sqrt(mean_squared_error(ytest, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "train['xgboost'] = xg_reg.predict(xtrain)\n",
    "test['xgboost']=preds\n",
    "\n",
    "XGB_confidence = xg_reg.score(xtest, ytest)\n",
    "xgb_mse = mean_squared_error(ytest, test['xgboost'])\n",
    "XGB_confidence,xgb_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 18\n",
    "# Convert the training and testing sets into DMatrixes: DM_train, DM_test\n",
    "DM_train = xgb.DMatrix(data=xtrain,label=ytrain)\n",
    "DM_test =  xgb.DMatrix(data=xtest,label=ytest)\n",
    "\n",
    "# Create the parameter dictionary: params\n",
    "params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "\n",
    "# Train the model: xg_reg\n",
    "xg_reg2 = xgb.train(params = params, dtrain=DM_train, num_boost_round=5)\n",
    "\n",
    "# Predict the labels of the test set: preds\n",
    "preds = xg_reg2.predict(DM_test)\n",
    "train['xgboost_matric'] = xg_reg2.predict(DM_train)\n",
    "test['xgboost_matric']=preds\n",
    "# Compute and print the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(ytest,preds))\n",
    "xgb_metric_mse = mean_squared_error(ytest, preds)\n",
    "xbg_metric_confidence = 1- sum((ytest - preds)**2)/sum((ytest - ytest.mean())**2)\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "print('Prediction: %.3f' % preds[0])\n",
    "xbg_metric_confidence,xgb_metric_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 19\n",
    "# LGBM\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "\n",
    "# Create the training and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'linear_tree': True,\n",
    "}\n",
    "#LGBM = LGBMRegressor(**params)\n",
    "LGBM = LGBMRegressor()\n",
    "\n",
    "# Fit the regressor to the training set\n",
    "LGBM.fit(xtrain, ytrain)\n",
    "train['lgbm'] = LGBM.predict(xtrain)\n",
    "test['lgbm']=LGBM.predict(xtest)\n",
    "LGBM_confidence = LGBM.score(xtest, ytest)\n",
    "LGBM_mse = mean_squared_error(ytest, test['lgbm'])\n",
    "LGBM_confidence, LGBM_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 20\n",
    "# support vector machine\n",
    "svr = SVR()\n",
    "svr.fit(xtrain, ytrain)\n",
    "train['svr'] = svr.predict(xtrain)\n",
    "test['svr']=svr.predict(xtest)\n",
    "svr_confidence = svr.score(xtest, ytest)\n",
    "svr_mse = mean_squared_error(ytest, test['svr'])\n",
    "svr_confidence, svr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 21\n",
    "# Compare performence of each model\n",
    "\n",
    "names = ['Linear Regression', 'Random Forest', 'Ridge', 'SVR', 'XGBoost', 'XGBoost_metric', 'LGBM']\n",
    "columns = ['model', 'accuracy']\n",
    "scores = [lr_confidence, rf_confidence, rg_confidence, svr_confidence, XGB_confidence, xbg_metric_confidence, LGBM_confidence]\n",
    "alg_vs_score = pd.DataFrame([[x, y] for x, y in zip(names, scores)], columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 22\n",
    "alg_vs_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 23\n",
    "fig = px.bar(alg_vs_score, y='accuracy', x='model',\n",
    "            title=\"Performance of Different Models\", color=\"model\", hover_name=\"accuracy\",\n",
    "             color_discrete_sequence=px.colors.qualitative.Pastel\n",
    "             )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 24\n",
    "names = ['Linear Regression', 'Random Forest', 'Ridge', 'SVR', 'XGBoost', 'XGBoost_metric','LGBM']\n",
    "columns_mse = ['model', 'mean_square_error']\n",
    "scores_mse = [lr_mse, rf_mse, rg_mse, svr_mse, xgb_mse, xgb_metric_mse,LGBM_mse]\n",
    "alg_vs_mse = pd.DataFrame([[x, y] for x, y in zip(names, scores_mse)], columns = columns_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 25\n",
    "alg_vs_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Cell 26\n",
    "fig_mse = px.bar(alg_vs_mse, y='mean_square_error', x='model',\n",
    "            title=\"Performance of Different Models\", color=\"model\", hover_name=\"mean_square_error\",\n",
    "             color_discrete_sequence=px.colors.qualitative.Pastel\n",
    "             )\n",
    "\n",
    "fig_mse.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 27\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 28\n",
    "train.corr().loc['V_C_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 29\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 30\n",
    "# variable correlation with V_Close\n",
    "test.corr().loc['V_C_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 31\n",
    "# predict new data\n",
    "newdata = pd.read_csv('C:/0-Ubi/S_Value_4.csv')\n",
    "newdata2 = newdata.copy()\n",
    "newdata.columns = newdata.columns.str.replace('[', '')\n",
    "newdata.columns = newdata.columns.str.replace(']', '')\n",
    "newdata.drop(['DT_ID','Date',\n",
    " 'Time',\n",
    "] ,axis=1, inplace=True)\n",
    "newy = newdata.V_Close\n",
    "newx = newdata.drop(['V_C_target'], axis = 1)\n",
    "newx.iloc[:,:] = scaler.fit_transform(newx.iloc[:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 32\n",
    "newx.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 33\n",
    "newdata2['linear_regression']=lr.predict(newx)\n",
    "newdata2['random_forest']=rf.predict(newx)\n",
    "newdata2['ridge'] = rg.predict(newx)\n",
    "newdata2['xgboost'] = xg_reg.predict(newx)\n",
    "newdata2['xgboost_metric'] = xg_reg2.predict(xgb.DMatrix(data=newx,label=newy))\n",
    "newdata2['lgbm'] = LGBM.predict(newx)\n",
    "newdata2['svm'] = svr.predict(newx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 34\n",
    "newdata2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 35\n",
    "newdata2.corr().loc['V_C_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 36\n",
    "# close distribution in train, test, an newdata\n",
    "plt.hist(train['V_C_target'],label='train')\n",
    "plt.hist(test['V_C_target'],label='test')\n",
    "plt.hist(newdata2['V_C_target'],label='newdata')\n",
    "plt.legend(ncol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 37\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 38\n",
    "newdata2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 39\n",
    "# save result\n",
    "train.to_csv('C:/0-Ubi/train_S_Value_4.csv')\n",
    "test.to_csv('C:/0-Ubi/test_S_Value_4.csv')\n",
    "newdata2.to_csv('C:/0-Ubi/newdata_S_Value_4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************End***********************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 40\n",
    "# run cell 1 to 11 before running this session\n",
    "n_run = 100\n",
    "newdata = pd.read_csv('C:/0-Ubi/S_Value_4.csv')\n",
    "newdata3 = newdata.copy()\n",
    "newdata.columns = newdata.columns.str.replace('[', '')\n",
    "newdata.columns = newdata.columns.str.replace(']', '')\n",
    "newdata.drop(['DT_ID','Date',\n",
    " 'Time',\n",
    "] ,axis=1, inplace=True)\n",
    "newy = newdata.V_Close\n",
    "newx_orig = newdata.drop(['V_C_target'], axis = 1)\n",
    "for i in range(n_run):\n",
    "    xtrain, xtest, ytrain,ytest = train_test_split(x,y,test_size = 0.3)\n",
    "    scaler = StandardScaler()\n",
    "    xtrain.iloc[:,:] = scaler.fit_transform(xtrain.iloc[:,:])\n",
    "    xtest.iloc[:,:] = scaler.transform(xtest.iloc[:,:])\n",
    "    newx = newx_orig.copy()\n",
    "    newx.iloc[:,:] = scaler.transform(newx.iloc[:,:])\n",
    "    # linear regression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(xtrain, ytrain)\n",
    "    newdata3['linear_reg'+str(i)] = lr.predict(newx)\n",
    "    #ranom forest\n",
    "    rf = RandomForestRegressor()\n",
    "    rf.fit(xtrain, ytrain)\n",
    "    newdata3['rf'+str(i)] = rf.predict(newx)\n",
    "    #rige\n",
    "    rg = Ridge()\n",
    "    rg.fit(xtrain, ytrain)\n",
    "    newdata3['rg'+str(i)] = rg.predict(newx)\n",
    "    #xgboost\n",
    "    xg_reg = xgb.XGBRegressor(objective=\"reg:linear\", n_estimators=10, seed=123)\n",
    "    xg_reg.fit(xtrain, ytrain)\n",
    "    newdata3['xg_reg'+str(i)] = xg_reg.predict(newx)\n",
    "    #sgboost with matric transformation\n",
    "    DM_train = xgb.DMatrix(data=xtrain,label=ytrain)\n",
    "    DM_new =  xgb.DMatrix(data=newx,label=newy)\n",
    "    params = {\"booster\":\"gblinear\", \"objective\":\"reg:linear\"}\n",
    "    xg_reg2 = xgb.train(params = params, dtrain=DM_train, num_boost_round=5)\n",
    "    newdata3['xg_regm'+str(i)] = xg_reg2.predict(DM_new)\n",
    "    # LGBM\n",
    "    LGBM = LGBMRegressor()\n",
    "    LGBM.fit(xtrain, ytrain)\n",
    "    newdata3['lgbm'+str(i)] = LGBM.predict(newx)\n",
    "    # svm   \n",
    "    svr = SVR()\n",
    "    svr.fit(xtrain, ytrain)\n",
    "    newdata3['svr'+str(i)] = svr.predict(newx)\n",
    "\n",
    "# prediction average for each model\n",
    "newdata3['linear_reg_avg']  = newdata3[[j for j in newdata3.columns if 'linear_reg' in j]].mean(axis=1)\n",
    "newdata3['rf_avg']  = newdata3[[j for j in newdata3.columns if 'rf' in j]].mean(axis=1)\n",
    "newdata3['xg_reg_avg']  = newdata3[[j for j in newdata3.columns if 'xg_reg' in j]].mean(axis=1)\n",
    "newdata3['xg_regm_avg']  = newdata3[[j for j in newdata3.columns if 'xg_regm' in j]].mean(axis=1)\n",
    "newdata3['lgbm_avg']  = newdata3[[j for j in newdata3.columns if 'lgbm' in j]].mean(axis=1)\n",
    "newdata3['svr_avg']  = newdata3[[j for j in newdata3.columns if 'svr' in j]].mean(axis=1)    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 41\n",
    "newdata3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cell 42\n",
    "newdata3[['V_C_target','linear_reg_avg','rf_avg','xg_reg_avg','xg_regm_avg','lgbm_avg','svr_avg']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 43\n",
    "newdata3.to_csv('C:/0-Ubi/newdata_S_Value_4_prediction_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 44\n",
    "# save only the preiction, in case file have too many colunmns\n",
    "newdata3[['DT_ID','linear_reg_avg','rf_avg','xg_reg_avg','xg_regm_avg','lgbm_avg','svr_avg']].to_csv('C:/0-Ubi/newdata_S_Value_4_prediction_only_avg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 45\n",
    "newdata3[['DT_ID','linear_reg_avg','rf_avg','xg_reg_avg','xg_regm_avg','lgbm_avg','svr_avg']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
